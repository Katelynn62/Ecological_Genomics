# Ecological Genomics Notebook

## Author: Katelynn Warner  
### Affiliation:  University of Vermont Natural Resources PhD Student 
### E-mail contact: kwarner@uvm.edu


### Start Date: 2020-01-13
### End Date: 2020-05-08
### Project Descriptions:   





# Table of Contents:   
* [Entry 1: 2020-01-13, Monday](#id-section1)
* [Entry 2: 2020-01-14, Tuesday](#id-section2)
* [Entry 3: 2020-01-15, Wednesday](#id-section3)
* [Entry 4: 2020-01-16, Thursday](#id-section4)
* [Entry 5: 2020-01-17, Friday](#id-section5)
* [Entry 6: 2020-01-20, Monday](#id-section6)
* [Entry 7: 2020-01-21, Tuesday](#id-section7)
* [Entry 8: 2020-01-22, Wednesday](#id-section8)
* [Entry 9: 2020-01-23, Thursday](#id-section9)
* [Entry 10: 2020-01-24, Friday](#id-section10)
* [Entry 11: 2020-01-27, Monday](#id-section11)
* [Entry 12: 2020-01-28, Tuesday](#id-section12)
* [Entry 13: 2020-01-29, Wednesday](#id-section13)


* [Entry 14: 2020-01-30, Thursday](#id-section14)
* [Entry 15: 2020-01-31, Friday](#id-section15)
* [Entry 16: 2020-02-03, Monday](#id-section16)
* [Entry 17: 2020-02-04, Tuesday](#id-section17)
* [Entry 18: 2020-02-05, Wednesday](#id-section18)
* [Entry 19: 2020-02-06, Thursday](#id-section19)
* [Entry 20: 2020-02-07, Friday](#id-section20)
* [Entry 21: 2020-02-10, Monday](#id-section21)
* [Entry 22: 2020-02-11, Tuesday](#id-section22)
* [Entry 23: 2020-02-12, Wednesday](#id-section23)
* [Entry 24: 2020-02-13, Thursday](#id-section24)
* [Entry 25: 2020-02-14, Friday](#id-section25)
* [Entry 26: 2020-02-17, Monday](#id-section26)
* [Entry 27: 2020-02-18, Tuesday](#id-section27)
* [Entry 28: 2020-02-19, Wednesday](#id-section28)
* [Entry 29: 2020-02-20, Thursday](#id-section29)
* [Entry 30: 2020-02-21, Friday](#id-section30)
* [Entry 31: 2020-02-24, Monday](#id-section31)
* [Entry 32: 2020-02-25, Tuesday](#id-section32)
* [Entry 33: 2020-02-26, Wednesday](#id-section33)
* [Entry 34: 2020-02-27, Thursday](#id-section34)
* [Entry 35: 2020-02-28, Friday](#id-section35)
* [Entry 36: 2020-03-02, Monday](#id-section36)
* [Entry 37: 2020-03-03, Tuesday](#id-section37)
* [Entry 38: 2020-03-04, Wednesday](#id-section38)
* [Entry 39: 2020-03-05, Thursday](#id-section39)
* [Entry 40: 2020-03-06, Friday](#id-section40)
* [Entry 41: 2020-03-09, Monday](#id-section41)
* [Entry 42: 2020-03-10, Tuesday](#id-section42)
* [Entry 43: 2020-03-11, Wednesday](#id-section43)
* [Entry 44: 2020-03-12, Thursday](#id-section44)
* [Entry 45: 2020-03-13, Friday](#id-section45)
* [Entry 46: 2020-03-16, Monday](#id-section46)
* [Entry 47: 2020-03-17, Tuesday](#id-section47)
* [Entry 48: 2020-03-18, Wednesday](#id-section48)
* [Entry 49: 2020-03-19, Thursday](#id-section49)
* [Entry 50: 2020-03-20, Friday](#id-section50)
* [Entry 51: 2020-03-23, Monday](#id-section51)
* [Entry 52: 2020-03-24, Tuesday](#id-section52)
* [Entry 53: 2020-03-25, Wednesday](#id-section53)
* [Entry 54: 2020-03-26, Thursday](#id-section54)
* [Entry 55: 2020-03-27, Friday](#id-section55)
* [Entry 56: 2020-03-30, Monday](#id-section56)
* [Entry 57: 2020-03-31, Tuesday](#id-section57)
* [Entry 58: 2020-04-01, Wednesday](#id-section58)
* [Entry 59: 2020-04-02, Thursday](#id-section59)
* [Entry 60: 2020-04-03, Friday](#id-section60)
* [Entry 61: 2020-04-06, Monday](#id-section61)
* [Entry 62: 2020-04-07, Tuesday](#id-section62)
* [Entry 63: 2020-04-08, Wednesday](#id-section63)
* [Entry 64: 2020-04-09, Thursday](#id-section64)
* [Entry 65: 2020-04-10, Friday](#id-section65)
* [Entry 66: 2020-04-13, Monday](#id-section66)
* [Entry 67: 2020-04-14, Tuesday](#id-section67)
* [Entry 68: 2020-04-15, Wednesday](#id-section68)
* [Entry 69: 2020-04-16, Thursday](#id-section69)
* [Entry 70: 2020-04-17, Friday](#id-section70)
* [Entry 71: 2020-04-20, Monday](#id-section71)
* [Entry 72: 2020-04-21, Tuesday](#id-section72)
* [Entry 73: 2020-04-22, Wednesday](#id-section73)
* [Entry 74: 2020-04-23, Thursday](#id-section74)
* [Entry 75: 2020-04-24, Friday](#id-section75)
* [Entry 76: 2020-04-27, Monday](#id-section76)
* [Entry 77: 2020-04-28, Tuesday](#id-section77)
* [Entry 78: 2020-04-29, Wednesday](#id-section78)
* [Entry 79: 2020-04-30, Thursday](#id-section79)
* [Entry 80: 2020-05-01, Friday](#id-section80)
* [Entry 81: 2020-05-04, Monday](#id-section81)
* [Entry 82: 2020-05-05, Tuesday](#id-section82)
* [Entry 83: 2020-05-06, Wednesday](#id-section83)
* [Entry 84: 2020-05-07, Thursday](#id-section84)
* [Entry 85: 2020-05-08, Friday](#id-section85)

------
<div id='id-section1'/>   

### Entry 1: 2020-01-13, Monday.   



------
<div id='id-section2'/>   

### Entry 2: 2020-01-14, Tuesday.   



------
<div id='id-section3'/>   

### Entry 3: 2020-01-15, Wednesday.   



------
<div id='id-section4'/>   

### Entry 4: 2020-01-16, Thursday.   



------
<div id='id-section5'/>   

### Entry 5: 2020-01-17, Friday.   



------
<div id='id-section6'/>   

### Entry 6: 2020-01-20, Monday.   



------
<div id='id-section7'/>   

### Entry 7: 2020-01-21, Tuesday.   



------
<div id='id-section8'/>   

### Entry 8: 2020-01-22, Wednesday.   



------
<div id='id-section9'/>   

### Entry 9: 2020-01-23, Thursday.   



------
<div id='id-section10'/>   

### Entry 10: 2020-01-24, Friday.   



------
<div id='id-section11'/>   

### Entry 11: 2020-01-27, Monday.   



------
<div id='id-section12'/>   

### Entry 12: 2020-01-28, Tuesday.   



------
<div id='id-section13'/>   

### Entry 13: 2020-01-29, Wednesday.   

* sample size = 110 mother trees from 23 populations
* 80,000 120bp probes -> uniquely hybridized to a specific area
* paired ends: 150 on each side..., so if our strand is 400 bp, we are only missing 100 bp readings.
* single end: Can get 150 bp on one end of a 5'-> 3' DNA 
Pipeline: files will end in .fastq.gz - zip file. 
1. first thing we will do is visualize these (Program FastQC)
2. Clean raw data (Program: Tricommomatic)
* Visualize post trimming step to make sure it did what you wanted it to do (FastQC)
3. Map/Align those reads to the reference genome (Program bwa, input: *.fastq*, output: *.sam*(human readable file)
4. Post processing (samtools, sambamba)
5. Remove PCR duplicates
6. Calculate stats

Coding: 
* Because files are in *.fastq.gz* and are zipped, we cannot use standard bash tools that we learned in last class. 
1. R1 = forward read
2. R2 = reverse read
* zcat peaks into the gzipped file without actually unzipping it. 
1. *be sure to name your heading number otherwise your computer will spit out the contents without stopping* EX: zcat ___ | head -n 4
1. Within this, N refers to a base that did not get a good read.
3. Phred scores - what is the probability that the machine read the base *incorrectly*?
1. p=10^-38/10
2. p=10^-3.8
3. p=0.0038

Running the FastQC Program
##### I am working with the: _BRB_

Bash scripting
* start with 
1. #!/bin/bash - tells your script that you are working in bash
2. for file in /data/project_data/RS_ExomeSeq/fastq/edge_fastq/BRB*fastq.gz
3. To exit edit mode in script, click escape
4. *.sh* is a bash script
5. can rename file by old file name to move to new file name
6. Because our file is not rwxr--r--...(*rwr--r--r*)
1. chmod is a command to change permissions: u+x adds permissions to all users
7. Sync repo with github and then with your local machine - pull github repo...double click html to open the files. Can't open in bash.

#### Trimmomatic
1. Example script is located in cd /data/scripts

We want paired reads here...unpaired reads are lower quality data. 
* To do this, we need to create an R2 name based on the R1 name becuase the are identical...
1. BRB_01_R1_fastqc.gz
2. BRB_01_R2_fastqc.gz
* So we are saying that R1 variable is equal to the R2 variable... *got confused here*
* threads is a CPU in your computer. 
* *phred33* is a phred score..
* Reads are going to be put into the common space..Unpaired and paired reads to separate them. It will name each of the files based on the named variable...BRB_05_R1.cl.pd.fq ,etc.

cleaned paired reads are in *cd data/project_data/RS_ExomeSeq/fastq?edge_fastq/pairedcleanreads/*
* You should have probably 8 files in there. 





------
<div id='id-section14'/>   

### Entry 14: 2020-01-30, Thursday.   



------
<div id='id-section15'/>   

### Entry 15: 2020-01-31, Friday.   



------
<div id='id-section16'/>   

### Entry 16: 2020-02-03, Monday.   



------
<div id='id-section17'/>   

### Entry 17: 2020-02-04, Tuesday.   



------
<div id='id-section18'/>   

### Entry 18: 2020-02-05, Wednesday.   
Need to go through and fix the fastqc file.
##### Objectives
1. Review our progress on read cleaning and visualizing QC
2. Start mapping each set of cleaned reads to a reference genome
*  Made this script in R and transferred to Bash. 
3. Visualize sequence alignment files
4. Process our sam files by..
* converting to binary format and sorting our coordinates
* removing PCR duplicates
* indexing for fast future lookup
5. Calculate mapping stats to assess quality of the result
6. Learn how to put separate bash scripts into a "wrapper" that runs them all
* "The one script to rule them all" 

###### Mapping Cleaned and trimmed reads..
* Reference Genome..
* congenie.org ; Good reference for conifers 
* 12 Haploid chromosomes...24 total.
* What is the N50; how much of the genome is assembled into large contigs(?)
1. - - - -- -- -- --- --- --- **----** ------- -------- --------- ; sum = 668 Mb
2. Take 50% ^ = 334 Mb; start with the biggest contig and move towards smaller until you have reached a sum of 334 Mb. 
3. N50 is the smallest contig at which all of the sum of the larger to smaller contigs = 334 Mb. 
4. N50 = 101,375 bp in this case. 
5. N50 is usually a metric to understand the data you are looking at..
* You usually decide to use this to compare individuals within species.
* Generally speaking, bigger is better, because it gives you better spatial information
##### Code for Today 
1. We don't need to actually download the genome because it is already in a file in the directory...
2. This is a code for us to get the genome.
3. wget; handy tool for us to get info from the internet and download it.
```
cd /data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa
```

##### Code for the Wrapper script
```
# We will use this as a wrapper to run our different wrapping scripts
#!/bin/cash # What every script in bash begins with. 

```

##### Mapping
1. Using bwa...
```
bwa mem -t 1 -M ${ref}...
```
2. mem algorithm is fast and accurate for reads
3. -t = how many threads? (CPUs) we are setting 1, but you can up it to your choice on your own
4. -M; setting that labels a read with a special flag ; if when bwa maps it to the genome, it splits that read to more than one contig
* This is possible because our DNA is very fragmented, so our reads could be on two contigs that are close together on the same chromosome.
5. ${ref} = our reference genome
6. ${forward} = our forward read
7. ${reverse} = our  reverse read.

##### Writing loops in bash
for forward in [...] 
*do*
commands
commands
*done*


##### Reminders
When you push data to github, you need to then pull on Bash using the git pull command, in order to pull your data/scripts/etc into Bash
```
screen

bash mypipeline.sh

Cntrl A + cntrl D

screen -r # opens back up your mypipeline.sh

```
------
<div id='id-section19'/>   

### Entry 19: 2020-02-06, Thursday.   



------
<div id='id-section20'/>   

### Entry 20: 2020-02-07, Friday.   



------
<div id='id-section21'/>   

### Entry 21: 2020-02-10, Monday.   



------
<div id='id-section22'/>   

### Entry 22: 2020-02-11, Tuesday.   



------
<div id='id-section23'/>   

### Entry 23: 2020-02-12, Wednesday.   

#### Population Genomics Day 3
##### Class Objectives
1. Review our progress on mapping
2. Calculate mapping statistics to assess quality of the result
3. Visusalize sequence alignment files
4. Introduce use of genotype-likelihoods for analyzing diversity in low coverage sequences
5. Use the 'ANGSD' program to calcullate diversity stats, Fsts, and PCA
* Analysis of next generation sequencing data



##### Code for today
1. Look at a SAM file using 'head' and 'tail'
```
tail -n 100 BRB_04.sam 
```
A sam file is a tab delimited text file that stores information about the alignment of reads in a FASTQ file to reference genome or transcriptome. For each read in a FASTQ file, there's a line in the SAM file that includes;
1. the read, aka query name,
2. a FLAG (number with information about mapping success and orientation and whether the read is the left or right read)
3. the reference sequence name to hwich the read mapped
4. the leftmost position in the reference where the read mapped

2. Flagstat gives us some basic stats on our sam files
```
samtools flagstat BRB_01.sam
```
* 2379308 + 0 in total (QC-passed reads + QC-failed reads) = number of reads
134530 + 0 secondary = *number of reads that weren't duplicated?*
0 + 0 supplementary
0 + 0 duplicates
2241464 + 0 mapped (94.21% : N/A)
2244778 + 0 paired in sequencing
1122389 + 0 read1
1122389 + 0 read2
1380290 + 0 properly paired (61.49% : N/A) ; *how many reads were properly paired together*
2027840 + 0 with itself and mate mapped
79094 + 0 singletons (3.52% : N/A) ; *how many were singletons...mapped with no other mate*
633316 + 0 with mate mapped to a different chr
318077 + 0 with mate mapped to a different chr (mapQ>=5)

3. Write a loop to iterate through your individual files for the .bam files for flagstats
```
for file in ${output}/BWA/${mypop}*sorted.rmdup.bam
  
  do 
    f=${file/.sorted.rmdup.bam/}
    name=`basename ${f}`
    echo ${name} >> ${myrepo}/myresults/${mypop}.names.txt
    samtools flagstat ${file} | awk 'NR>=6&&NR<=12 {print $1}' | column -x
  done >> ${myrepo}/myresults/${mypop}.flagstats.txt
```
4.Calculate depth of coverage from our bam files
```
for file in ${output}/BWA/${mypop}*sorted.rmdup.bam

  do 
    samtools depth ${file} | awk '{sum+=$3} END {print sum/NR}' 
  done >> ${myrepo}/myresults/${mypop}.coverage.txt
```
5. Viewing your sequences
```
samtools tview /data/project_data/RS_ExomeSeq/mapping/BWA/BRB_01.sorted.rmdup.bam /data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa

```
![Visualize Sequences](â€ªC:\Users\kwarn\Pictures\Genomics_!.PNG)
Genotype likelihood is the best way to handle these kinds of data.
* Take the most probable.

6. Running ANGSD
1. Create list of bam files for samples you want to analyze
2. Estimate genotype likelihooda and allele frequencies after filtering to minimize noise 
3. Use GL's to:
* a. Estimate the SFS
* b. Estimate nucleotide diversities
* c. estimate fst between all populations, or pairwise between sets of populations
* d. perform a genetic PCA based on the estimation of genetic covariance matrix
4. In myscripts, create ANGSD_mypop.sh
```
REF="/data/project_data/RS_ExomeSeq/ReferenceGenomes/Pabies1.0-genome_reduced.fa"

# Estimating GL's and allele frequencies for all sites with ANGSD

ANGSD -b ${output}/${mypop}_bam.list \
-ref ${REF} -anc ${REF} \
-out ${output}/${mypop}_allsites \
-nThreads 1 \
-remove_bads 1 \
-C 50 \
-baq 1 \
-minMapQ 20 \
-minQ 20 \
-setMinDepth 3 \
-minInd 2 \
-setMinDepthInd 1 \
-setMaxDepthInd 17 \
-skipTriallelic 1 \
-GL 1 \
-doCounts 1 \
-doMajorMinor 1 \
-doMaf 1 \
-doSaf 1 \
-doHWE 1 \
# -SNP_pval 1e-6
```
* if we wanted to just the polymorphic sites we would uncomment out the -SNP_pval call. 

##### Helpful bits of Code
1. Reverse order of a list by the time the file was stamped
```
ll -rt
```
2. look at specific files in a folder. This allows you to look at all BRB sam files.
```
 ll BRB*.sam
```
3. Look at first ten rows
```
head BRB_01.sam
```
* Each row of the head is the name of contig and its length in bp (LN)
4. Look at the bottom ten rows
```
tail BRB_01.sam
```
* GWNJ-0842:368:GW1809211440:2:2224:19167:72983   163     MA_186154       822    40       13M1I41M3S      =       1191    469     AAGGAAANGGNGGNGGAATAGTGATGNGAAGTGTTAAGTATGGTCANGAACGGTACNA      AAFJJJJ#FJ#JJ#JJJJJJJJ<<FF#FFJJAJ-FJFFFFJJJJJJ#JJJFJJJJF#F      NM:i:9  MD:Z:7T2A8A5G0A5G11T0A8 AS:i:19 XS:i:0
1. basically the ID of the read - GWNJ-0842:368:GW1809211440:2:2224:19167:72983
2. 163 = flag ; can be interpretated by going to a flag decoder. The read was paired, mapped in a proper pair, mate reverse strand, second in pair.
3. MA_186154; contig in P.abies that the read mapped to
4. 822 ; left most position in the read
5. 40; mapping quality in phred scale. Very unlikely that the read was mapped to the reference genome incorrectly.

------
<div id='id-section24'/>   

### Entry 24: 2020-02-13, Thursday.   



------
<div id='id-section25'/>   

### Entry 25: 2020-02-14, Friday.   



------
<div id='id-section26'/>   

### Entry 26: 2020-02-17, Monday.   



------
<div id='id-section27'/>   

### Entry 27: 2020-02-18, Tuesday.   



------
<div id='id-section28'/>   

### Entry 28: 2020-02-19, Wednesday.   

#### Population Genomics Day 3:

##### Notes

##### Code for today
1.
```
```
2.
```
```
3.
```
```
4.
```
```
5.
```
```
6.
```
```
7. 
```
```
8. 
```
```
9.
```
```
10.
```
```


------
<div id='id-section29'/>   

### Entry 29: 2020-02-20, Thursday.   



------
<div id='id-section30'/>   

### Entry 30: 2020-02-21, Friday.   



------
<div id='id-section31'/>   

### Entry 31: 2020-02-24, Monday.   



------
<div id='id-section32'/>   

### Entry 32: 2020-02-25, Tuesday.   



------
<div id='id-section33'/>   

### Entry 33: 2020-02-26, Wednesday.   



------
<div id='id-section34'/>   

### Entry 34: 2020-02-27, Thursday.   



------
<div id='id-section35'/>   

### Entry 35: 2020-02-28, Friday.   



------
<div id='id-section36'/>   

### Entry 36: 2020-03-02, Monday.   



------
<div id='id-section37'/>   

### Entry 37: 2020-03-03, Tuesday.   



------
<div id='id-section38'/>   

### Entry 38: 2020-03-04, Wednesday.   



------
<div id='id-section39'/>   

### Entry 39: 2020-03-05, Thursday.   



------
<div id='id-section40'/>   

### Entry 40: 2020-03-06, Friday.   



------
<div id='id-section41'/>   

### Entry 41: 2020-03-09, Monday.   



------
<div id='id-section42'/>   

### Entry 42: 2020-03-10, Tuesday.   



------
<div id='id-section43'/>   

### Entry 43: 2020-03-11, Wednesday.   



------
<div id='id-section44'/>   

### Entry 44: 2020-03-12, Thursday.   



------
<div id='id-section45'/>   

### Entry 45: 2020-03-13, Friday.   



------
<div id='id-section46'/>   

### Entry 46: 2020-03-16, Monday.   



------
<div id='id-section47'/>   

### Entry 47: 2020-03-17, Tuesday.   



------
<div id='id-section48'/>   

### Entry 48: 2020-03-18, Wednesday.   



------
<div id='id-section49'/>   

### Entry 49: 2020-03-19, Thursday.   



------
<div id='id-section50'/>   

### Entry 50: 2020-03-20, Friday.   



------
<div id='id-section51'/>   

### Entry 51: 2020-03-23, Monday.   



------
<div id='id-section52'/>   

### Entry 52: 2020-03-24, Tuesday.   



------
<div id='id-section53'/>   

### Entry 53: 2020-03-25, Wednesday.   



------
<div id='id-section54'/>   

### Entry 54: 2020-03-26, Thursday.   



------
<div id='id-section55'/>   

### Entry 55: 2020-03-27, Friday.   



------
<div id='id-section56'/>   

### Entry 56: 2020-03-30, Monday.   



------
<div id='id-section57'/>   

### Entry 57: 2020-03-31, Tuesday.   



------
<div id='id-section58'/>   

### Entry 58: 2020-04-01, Wednesday.   



------
<div id='id-section59'/>   

### Entry 59: 2020-04-02, Thursday.   



------
<div id='id-section60'/>   

### Entry 60: 2020-04-03, Friday.   



------
<div id='id-section61'/>   

### Entry 61: 2020-04-06, Monday.   



------
<div id='id-section62'/>   

### Entry 62: 2020-04-07, Tuesday.   



------
<div id='id-section63'/>   

### Entry 63: 2020-04-08, Wednesday.   



------
<div id='id-section64'/>   

### Entry 64: 2020-04-09, Thursday.   



------
<div id='id-section65'/>   

### Entry 65: 2020-04-10, Friday.   



------
<div id='id-section66'/>   

### Entry 66: 2020-04-13, Monday.   



------
<div id='id-section67'/>   

### Entry 67: 2020-04-14, Tuesday.   



------
<div id='id-section68'/>   

### Entry 68: 2020-04-15, Wednesday.   



------
<div id='id-section69'/>   

### Entry 69: 2020-04-16, Thursday.   



------
<div id='id-section70'/>   

### Entry 70: 2020-04-17, Friday.   



------
<div id='id-section71'/>   

### Entry 71: 2020-04-20, Monday.   



------
<div id='id-section72'/>   

### Entry 72: 2020-04-21, Tuesday.   



------
<div id='id-section73'/>   

### Entry 73: 2020-04-22, Wednesday.   



------
<div id='id-section74'/>   

### Entry 74: 2020-04-23, Thursday.   



------
<div id='id-section75'/>   

### Entry 75: 2020-04-24, Friday.   



------
<div id='id-section76'/>   

### Entry 76: 2020-04-27, Monday.   



------
<div id='id-section77'/>   

### Entry 77: 2020-04-28, Tuesday.   



------
<div id='id-section78'/>   

### Entry 78: 2020-04-29, Wednesday.   



------
<div id='id-section79'/>   

### Entry 79: 2020-04-30, Thursday.   



------
<div id='id-section80'/>   

### Entry 80: 2020-05-01, Friday.   



------
<div id='id-section81'/>   

### Entry 81: 2020-05-04, Monday.   



------
<div id='id-section82'/>   

### Entry 82: 2020-05-05, Tuesday.   



------
<div id='id-section83'/>   

### Entry 83: 2020-05-06, Wednesday.   



------
<div id='id-section84'/>   

### Entry 84: 2020-05-07, Thursday.   



------
<div id='id-section85'/>   

### Entry 85: 2020-05-08, Friday.   
